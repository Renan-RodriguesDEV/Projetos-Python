{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440be4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# libs necessarias\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b886e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando as imagens\n",
    "data_base_path = r'C:\\Users\\User\\Downloads\\Imagens\\train'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bb9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definido o tamanho do lote, largura e altura das imagens\n",
    "batch_size = 32\n",
    "img_width,img_height = 180,180\n",
    "epochs = 20\n",
    "learning_rate = 0.0001  # Taxa de aprendizagem para o otimizador\n",
    "print(img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189747bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando o conjunto de dados em treinamento e validação\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_base_path,\n",
    "    shuffle = True,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    subset=\"training\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split = 1/3\n",
    "    \n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_base_path,\n",
    "    shuffle = True,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    subset=\"validation\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=1/3,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_classes=train_ds.class_names\n",
    "nomes_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exibindo algumas imagens de treinamento\n",
    "def plot_img(dataset):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            plt.title(nomes_classes[labels[i]])\n",
    "            plt.axis(\"off\")\n",
    "    plt.show()\n",
    "plot_img(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b9160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_img(val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classe=len(nomes_classes)\n",
    "num_classe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações automáticas de desempenho\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Preparação dos dados de treinamento\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Preparação dos dados de validação\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357c8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização das imagens\n",
    "shape=(img_width,img_height,3)\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = layers.Rescaling(1./255)  # Normaliza os valores dos pixels das imagens para o intervalo [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59425c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalizador(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f8e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo de rede neural\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=shape),# Camada de normalização\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),  # Camada convolucional\n",
    "    layers.MaxPooling2D(2,2),  # Camada de max pooling\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),  # Camada convolucional\n",
    "    layers.MaxPooling2D(2,2),  # Camada de max pooling\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),  # Camada convolucional\n",
    "    layers.MaxPooling2D(2,2),  # Camada de max pooling\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),  # Camada de flatten para transformar a saída em um vetor unidimensional\n",
    "    layers.Dense(128, activation='relu'),  # Camada densa (totalmente conectada)\n",
    "    layers.Dense(num_classe,activation='softmax')  # Camada de saída com ativação sigmoid para classificação\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1621b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cbd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Treinando o modelo\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98cba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "faixa_epochs = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(faixa_epochs, acc, label='Treino Accuracy')\n",
    "plt.plot(faixa_epochs, val_acc, label='Validacao Accuracy')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Treino and Validacao Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(faixa_epochs, loss, label='Treino Loss')\n",
    "plt.plot(faixa_epochs, val_loss, label='Validacao Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Treino and Validacao Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_one_img(img,score):\n",
    "    # Plotar a imagem\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Classificada como {nomes_classes[np.argmax(score)]}\\ncom uma precisão de {100 * np.max(score):.2f}%')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def classificar_for_wpp(path_img):\n",
    "    img = tf.keras.utils.load_img(\n",
    "        path_img, target_size=(img_height, img_width)\n",
    "    )\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    plot_one_img(img,score)\n",
    "    print(\n",
    "        f\"classificada como {nomes_classes[np.argmax(score)]} \\ncom uma accuracy de {100 * np.max(score):.2f} %.\"\n",
    "    )\n",
    "classificar_for_wpp(r'C:\\Users\\User\\Desktop\\modelo_classifier\\imagens_para_teste\\mediana (16).jpg')\n",
    "classificar_for_wpp(r'C:\\Users\\User\\Desktop\\modelo_classifier\\imagens_para_teste\\uniforme (13).jpg')\n",
    "classificar_for_wpp(r'C:\\Users\\User\\Desktop\\modelo_classifier\\imagens_para_teste\\escassa (31).jpg')\n",
    "# import os\n",
    "# path=(r'C:\\Users\\User\\Downloads\\Imagens\\Escassa')\n",
    "# for imagem in os.listdir(path):\n",
    "#         classificar_for_wpp(os.path.join(path,imagem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c771cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\", input_shape=shape),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dde03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255, input_shape=shape),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(2, 2),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(2, 2),\n",
    "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(2, 2),\n",
    "  layers.Dropout(0.5),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(256, activation='relu'),\n",
    "  layers.Dropout(0.5),\n",
    "  layers.Dense(num_classe, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b63243",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, min_lr=0.00001)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1fca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificar_for_wpp(r'C:\\Users\\User\\Desktop\\modelo_classifier\\imagens_para_teste\\mediana (16).jpg')\n",
    "classificar_for_wpp(r'C:\\Users\\User\\Desktop\\modelo_classifier\\imagens_para_teste\\uniforme (13).jpg')\n",
    "classificar_for_wpp(r'C:\\Users\\User\\Desktop\\modelo_classifier\\imagens_para_teste\\escassa (31).jpg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
